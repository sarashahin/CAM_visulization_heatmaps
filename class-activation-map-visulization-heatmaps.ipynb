{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**class activation map visulization by heatmaps(CAM)**\n","metadata":{}},{"cell_type":"code","source":"# loading the VGG16 network with pretrained weights\n\nfrom keras.applications.vgg16 import VGG16\n\nmodel = VGG16(weights = 'imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:06.435757Z","iopub.execute_input":"2022-01-18T19:40:06.436168Z","iopub.status.idle":"2022-01-18T19:40:08.568859Z","shell.execute_reply.started":"2022-01-18T19:40:06.436119Z","shell.execute_reply":"2022-01-18T19:40:08.567699Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"# preprocessing an input image for VGG16\n\nfrom keras.preprocessing import image\n\nfrom tensorflow.keras.applications.vgg16 import decode_predictions\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\nimg_path = '../input/elephant/Elephants.jpeg'\nimg = image.load_img(img_path, target_size=(224, 224)) #resize to 224, 224\nx = image.img_to_array(img) #float32 numpy array of shape\nx = np.expand_dims(x, axis=0)#add dimension to transform the array into batch of size\n\nx = preprocess_input(x)# preprocess the batch \n\npreds = model.predict(x)\nprint(\"Predicted:\", decode_predictions(preds, top=3)[0])\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:08.570546Z","iopub.execute_input":"2022-01-18T19:40:08.570915Z","iopub.status.idle":"2022-01-18T19:40:09.113313Z","shell.execute_reply.started":"2022-01-18T19:40:08.570871Z","shell.execute_reply":"2022-01-18T19:40:09.112613Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"input_img = x / 255\nplt.imshow(input_img[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:09.114143Z","iopub.execute_input":"2022-01-18T19:40:09.114350Z","iopub.status.idle":"2022-01-18T19:40:09.335902Z","shell.execute_reply.started":"2022-01-18T19:40:09.114325Z","shell.execute_reply":"2022-01-18T19:40:09.335132Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"# maximally activated\nnp.argmax(preds[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:09.337795Z","iopub.execute_input":"2022-01-18T19:40:09.338240Z","iopub.status.idle":"2022-01-18T19:40:09.343675Z","shell.execute_reply.started":"2022-01-18T19:40:09.338203Z","shell.execute_reply":"2022-01-18T19:40:09.342988Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"# setting up the grand_cam algorithm\nimport cv2\nimport tensorflow as tf\nfrom keras import backend as K\n\nafrican_elephant_output_inx = 400\n\n\nlast_conv_layer = model.get_layer('block5_conv3')#the last convolutional layer in vgg16\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:09.344911Z","iopub.execute_input":"2022-01-18T19:40:09.345151Z","iopub.status.idle":"2022-01-18T19:40:09.354881Z","shell.execute_reply.started":"2022-01-18T19:40:09.345123Z","shell.execute_reply":"2022-01-18T19:40:09.354159Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n# Construct the gradient model by supplying:\\n\",\n# (1) the inputs to our pre-trained model;\\n\",\n# (2) the output of the last convolutional layer in the network;\\n\",\n# (3) the output of the softmax activations from the model\\n\",\n\n# grads = k.gradients(cat_dog_ouput_inx, last_conv_laye.output)[0]\n\ngrad_model = tf.keras.models.Model([model.inputs], [last_conv_layer.output, model.output])","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:09.355892Z","iopub.execute_input":"2022-01-18T19:40:09.356494Z","iopub.status.idle":"2022-01-18T19:40:09.372564Z","shell.execute_reply.started":"2022-01-18T19:40:09.356461Z","shell.execute_reply":"2022-01-18T19:40:09.371748Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"# Set up GradientTape for automatic differentiation\\n\",\nwith tf.GradientTape() as tape:\n    # pass the image through the gradient model, and grab the loss associated with the specific class index\\n\",\n    conv_outputs, predictions = grad_model(x)\n    loss = predictions[:, african_elephant_output_inx]\n\noutput = conv_outputs[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:09.373707Z","iopub.execute_input":"2022-01-18T19:40:09.374010Z","iopub.status.idle":"2022-01-18T19:40:09.710711Z","shell.execute_reply.started":"2022-01-18T19:40:09.373971Z","shell.execute_reply":"2022-01-18T19:40:09.709798Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"# Compute the gradients of the \\\"African elephant\\\" class with regard to the output \\n\",\n# feature map of block5_conv3, given a sample image\\n\",\ngrads = tape.gradient(loss, conv_outputs)[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:09.712082Z","iopub.execute_input":"2022-01-18T19:40:09.712396Z","iopub.status.idle":"2022-01-18T19:40:10.650192Z","shell.execute_reply.started":"2022-01-18T19:40:09.712353Z","shell.execute_reply":"2022-01-18T19:40:10.649375Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"# Vector of shape (512), where each entry is the mean intensity of the gradient over a specific feature map channel\\n\",\nweights = tf.reduce_mean(grads, axis=(0, 1))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:10.651734Z","iopub.execute_input":"2022-01-18T19:40:10.652037Z","iopub.status.idle":"2022-01-18T19:40:10.657693Z","shell.execute_reply.started":"2022-01-18T19:40:10.651997Z","shell.execute_reply":"2022-01-18T19:40:10.657064Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"# Multiplies each channel in feature-map array by \\\"how important this channel is\\\" with regard to the elephant class.\\n\",\ncam = tf.multiply(weights, output)\n\n# The channel-wise mean of the resulting feature map is the heatmap of the class activation!\\n\",\nheatmap = tf.reduce_mean(cam, axis=-1).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:10.659755Z","iopub.execute_input":"2022-01-18T19:40:10.660367Z","iopub.status.idle":"2022-01-18T19:40:10.673677Z","shell.execute_reply.started":"2022-01-18T19:40:10.660329Z","shell.execute_reply":"2022-01-18T19:40:10.672965Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"#### Visualize the heatmap\"\n    \n# Postprocessing heatmap\\n\",\nheatmap = (heatmap - np.min(heatmap)) / (heatmap.max() - heatmap.min())\nplt.matshow(heatmap)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:10.675249Z","iopub.execute_input":"2022-01-18T19:40:10.675765Z","iopub.status.idle":"2022-01-18T19:40:10.974084Z","shell.execute_reply.started":"2022-01-18T19:40:10.675722Z","shell.execute_reply":"2022-01-18T19:40:10.973140Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"### Generate superimposed original image over the heatmap\"\n# Use cv2 to load the original image\\n\",\ncv_img = cv2.imread(img_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:10.975841Z","iopub.execute_input":"2022-01-18T19:40:10.976371Z","iopub.status.idle":"2022-01-18T19:40:11.004482Z","shell.execute_reply.started":"2022-01-18T19:40:10.976324Z","shell.execute_reply":"2022-01-18T19:40:11.003431Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"# Resize the heatmap to be the same as the original image\\n\",\nheatmap = cv2.resize(heatmap, (cv_img.shape[1], cv_img.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:11.006308Z","iopub.execute_input":"2022-01-18T19:40:11.006905Z","iopub.status.idle":"2022-01-18T19:40:11.015626Z","shell.execute_reply.started":"2022-01-18T19:40:11.006853Z","shell.execute_reply":"2022-01-18T19:40:11.014607Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"# Converts heatmap to RBG\\n\",\nheatmap = (heatmap * 255).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:11.017787Z","iopub.execute_input":"2022-01-18T19:40:11.018442Z","iopub.status.idle":"2022-01-18T19:40:11.025103Z","shell.execute_reply.started":"2022-01-18T19:40:11.018319Z","shell.execute_reply":"2022-01-18T19:40:11.023989Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"# Apply a color map to the heatmap\\n\",\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:11.027171Z","iopub.execute_input":"2022-01-18T19:40:11.027813Z","iopub.status.idle":"2022-01-18T19:40:11.040021Z","shell.execute_reply.started":"2022-01-18T19:40:11.027763Z","shell.execute_reply":"2022-01-18T19:40:11.039009Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"# Applies the heatmap to the original image. The variable alpha is a heatmap intensity factor\\n\",\nalpha = 0.4\noutput_image = cv2.addWeighted(cv_img, alpha, heatmap, 1 - alpha, 0)\n\n\n\ncv2.imwrite('../input/elephant/Elephants.jpeg', output_image)\n\nplt.imshow(output_image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:40:11.042443Z","iopub.execute_input":"2022-01-18T19:40:11.042732Z","iopub.status.idle":"2022-01-18T19:40:11.323238Z","shell.execute_reply.started":"2022-01-18T19:40:11.042690Z","shell.execute_reply":"2022-01-18T19:40:11.322411Z"},"trusted":true},"execution_count":251,"outputs":[]}]}